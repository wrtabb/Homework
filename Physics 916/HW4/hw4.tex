\documentclass{article}

\usepackage{hyperref}
\usepackage{fancyhdr}
\usepackage{braket}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{mathtools}
\usepackage{graphicx}
\graphicspath{ {./Images/} }

\DeclarePairedDelimiter\abs{\lvert}{\rvert}%
\DeclarePairedDelimiter\norm{\lVert}{\rVert}%

\makeatletter
\let\oldabs\abs
\def\abs{\@ifstar{\oldabs}{\oldabs*}}
%
\let\oldnorm\norm
\def\norm{\@ifstar{\oldnorm}{\oldnorm*}}
\makeatother

\newcommand*{\Value}{\frac{1}{2}x^2}%

\usetikzlibrary{automata,positioning}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

%
% Create Problem Sections
%

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

%
% Homework Problem Environment
%
% This environment takes an optional argument. When given, it will adjust the
% problem counter. This is useful for when the problems given for your
% assignment aren't sequential. See the last 3 problems of this template for an
% example.
%
\newenvironment{homeworkProblem}[1][-1]{
    \ifnum#1>0
        \setcounter{homeworkProblemCounter}{#1}
    \fi
    \section{Problem \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}

%
% Homework Details
%   - Title
%   - Due date
%   - Class
%   - Section/Time
%   - Instructor
%   - Author
%

\newcommand{\hmwkTitle}{Homework\ \#4}
\newcommand{\hmwkDueDate}{April 13, 2020}
\newcommand{\hmwkClass}{Physics 916}
\newcommand{\hmwkClassTime}{}
\newcommand{\hmwkClassInstructor}{Professor Jean Marcel Ngoko}
\newcommand{\hmwkAuthorName}{\textbf{Robert Tabb}}

%
% Title Page
%

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
    \vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
    \vspace{3in}
}

\author{\hmwkAuthorName}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

%
% Various Helper Commands
%

% Useful for algorithms
\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}

% For derivatives
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}

% For partial derivatives
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}

% Integral dx
\newcommand{\dx}{\mathrm{d}x}

% Alias for the Solution section header
\newcommand{\solution}{\textbf{\large Solution}}

% Probability commands: Expectation, Variance, Covariance, Bias
\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Bias}{\mathrm{Bias}}

\begin{document}

\maketitle

\pagebreak

\begin{homeworkProblem}
	Consider a physical system whose three-dimensional state space is spanned by an
	orthonormal basis $\{\ket{u_1},\ket{u_2},\ket{u_3}\}$. In that state space, consider two operators $L_z$ and S defined by:
	\[
		\begin{split}
		L_z\ket{u_1}=&\ket{u_1}, L_z\ket{u_2}=\ket{0}, L_z\ket{u_3}=-\ket{u_3} \\
		S\ket{u_1}=&\ket{u_3}, S\ket{u_2}=\ket{u_2}, S\ket{u_3}=\ket{u_1}
		\end{split}
	\]
	(a) Write the matrices which represent, in the $\{\ket{u_1},\ket{u_2},\ket{u_3}\}$ basis, the operators $L_z,L_z^2,S,$ and $S^2$. Are these operators observables? 
	\\
	\\
	(b) Give the form of the most general matrix, which represents an operator which
	commutes with $L_z$. Same for $L_z^2$ and $S^2$.
	\\
	\\
	(c) Do $L_z^2$ and $S^2$ form a CSCO? Give a basis of common eigenvectors.
	\\
	\\
	\textbf{Solution}
	\\
	\\
	\textbf{Part a}
	\\
	\\
	The matrix representation of these two operators is found by applying to each $\ket{u_i}$ and simply seeing what each row and column must be to bring about the given transformations. They are:
	\[
		L_z = \begin{pmatrix}
		1 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 &-1
		\end{pmatrix}, \quad
		S = \begin{pmatrix}
		0 & 0 & 1\\
		0 & 1 & 0 \\
		1 & 0 & 0
		\end{pmatrix}
	\]
	Then we square them to get the other two matrices:
	\[
		L_z^2 = \begin{pmatrix}
		1 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 & 1
		\end{pmatrix}, \quad
		S^2 = \begin{pmatrix}
		1 & 0 & 0\\
		0 & 1 & 0 \\
		0 & 0 & 1
		\end{pmatrix}
	\]
	These are all observables because they are Hermitian:
	\[
		\begin{split}
		L_z^\dagger =& L_z, (L_z^2)^\dagger=L_z^2 \\
		S^\dagger =& S, (S^2)^\dagger=S^2
		\end{split}
	\]
	\\
	\\
	\textbf{Part b}
	\\
	\\
	To find the most general matrix, A, which commutes with $L_z$, we need to solve:
	\[
		[L_z,A] = L_zA-AL_z = 0
	\]
	Let's define A in a general way as:
	\[
		A = \begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix}
	\]
	Then we have:
	\[
	\begin{split}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 &-1
		\end{pmatrix}
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix} = &
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 &-1
		\end{pmatrix}  \\
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		0 & 0 & 0 \\
		-a_{31} & -a_{32} & -a_{33}
		\end{pmatrix} =& 
		\begin{pmatrix}
		a_{11} & 0 & -a_{13} \\
		a_{21} & 0 & -a_{23} \\
		a_{31} & 0 & -a_{33}
		\end{pmatrix} \\
		\Rightarrow a_{11}=a_{11},\;a_{12}=0,\;a_{13}=-a_{13} \\
		a_{21}=0,\;a_{22}=a_{22},\;a_{23}=0 \\
		a_{31}=0,\;a_{32}=0,\;a_{33}=a_{33} \\
		\Rightarrow A = \begin{pmatrix}
		a_{11} & 0 & 0 \\
		0 & a_{22} & 0 \\
		0 & 0 & a_{33}
		\end{pmatrix}
	\end{split}
	\]
	Let's use the same general definition of A to find the general matrix which commutes with $L_z^2$:
	\[
		\begin{split}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 &1
		\end{pmatrix}
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix} = &
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 & 1
		\end{pmatrix}  \\
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		0 & 0 & 0 \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix} =& 
		\begin{pmatrix}
		a_{11} & 0 & a_{13} \\
		a_{21} & 0 & a_{23} \\
		a_{31} & 0 & a_{33}
		\end{pmatrix} \\
		\Rightarrow a_{11}=a_{11},\;a_{12}=0,\;a_{13}=a_{13} \\
		a_{21}=0,\;a_{22}=a_{22},\;a_{23}=0 \\
		a_{31}=a_{31},\;a_{32}=0,\;a_{33}=a_{33} \\
		\Rightarrow A = \begin{pmatrix}
		a_{11} & 0 & a_{13} \\
		0 & a_{22} & 0 \\
		a_{31} & 0 & a_{33}
		\end{pmatrix} 
		\end{split}
	\]
	And now for $S^2$:
	\[
		\begin{split}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 &1
		\end{pmatrix}
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix} = &
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1
		\end{pmatrix}  \\
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix} =& 
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix} \\
		A = 
		\begin{pmatrix}
		a_{11} & a_{12} & a_{13} \\
		a_{21} & a_{22} & a_{23} \\
		a_{31} & a_{32} & a_{33}
		\end{pmatrix}
		\end{split}
	\]
	The commuting matrix for $L_z$ must be diagonal, for $L_z^2$ it must have the structure shown above, and for $S^2$ everything commutes because $S^2=I$, the identity.
	\\
	\\
	\textbf{Part c}
	\\
	\\
	The first thing to note is that both $L_Z^2$ and $S^2$ are degenerate. This means that the eigenvalues of either alone cannot fully specify the state of a vector. 
	\\
	
	Next, I want to see if $L_z^2$ commutes with $S^2$. If you refer back to the matrix representation of $S^2$ from part a, you'll see that $S^2=I$, where I is the identity matrix. \(\Rightarrow [S^2,L_z^2]=[I,L_Z^2]=0\). 
	\\
	
	But do they form a CSCO? We can quickly find the eigenvectors for $L_z^2$. Since the matrix is diagonal, we can simply read off the eigenvalues, $\lambda=1,0$. Plugging these into the characteristic equation, we get:
	\\
	\\
	For $\lambda=0$:
	\[
		\begin{split}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 0 & 0\\
		0 & 0 & 1
		\end{pmatrix}
		\begin{pmatrix} c_1 \\ c_2 \\ c_3 \end{pmatrix} =& \begin{pmatrix} 0\\0\\0 \end{pmatrix} \\
		\Rightarrow c_1 = 0, c_3 =& 0 \\
		\ket{v_{\lambda=0}} = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}
		\end{split}
	\]
	For $\lambda=1$:
	\[
		\begin{split}
		\begin{pmatrix}
		0 & 0 & 0 \\
		0 &-1 & 0\\
		0 & 0 & 0
		\end{pmatrix}
		\begin{pmatrix} c_1 \\ c_2 \\ c_3 \end{pmatrix} =& \begin{pmatrix} 0\\0\\0 \end{pmatrix} \\
		\Rightarrow c_2 =& 0 \\
		\ket{v_{\lambda=1}} = \begin{pmatrix} 1 \\ 0 \\ 1 \end{pmatrix}
		\end{split}
	\]
	But we can split $\ket{v_{\lambda=1}}$ into two orthogonal vectors:
	\[
		\ket{v_{\lambda=1}}=\begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
	\]
	Renaming the vectors as $v_1,v_2,v_3$:
	\[
		\ket{v_1}=\begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}, \ket{v_2}=\begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}, \ket{v_3}=\begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
	\]
	Now we have three mutually orthogonal eigenvectors fully specifying the eigenspace. These are easy to check:
	\[
		\begin{split}
		L_z^2\ket{v_1} =& \ket{v_1}, \: S^2\ket{v_1} = \ket{v_1} \\
		L_z^2\ket{v_2} =& \ket{0}, \; S^2\ket{v_2} = \ket{v_2} \\
		L_z^2\ket{v_3} =& \ket{v_3}, \: S^2\ket{v_3} = \ket{v_3}
		\end{split}
	\]
	This has not gotten rid of our degeneracy. We still have $\lambda=1$ for $v_1$ and $v_3$. Thus, $L_z^2$ and $S^2$ do not form a CSCO. Also note; the choice of basis vectors here is not unique since $\ket{v_1}$ and $\ket{v_3}$ were chosen arbitrarily. There are an infinite number of vectors in the plane spanned by these that could act as orthonormal basis vectors for the eigenspace.
	
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
	(a) Consider a linear operator $A$ in a state space. Show that the trace of this operator is invariant under the change of basis. The trace of a matrix $A$, noted as $Tr\{A\}$, is defined as the sum of its diagonal elements.
	\\
	\\
	(b) Assume that the eigenvalues, $a_n$, of the observable $A$ are degenerate with a degree $g_n$. Calculate $Tr\{A\}$ in terms of the eigenvalues and the degree of degeneracy.
	\\
	\\
	\textbf{Solution}
	\\
	\\
	(a) We have a linear operator, $A$ and a unitary transformation $U$ which acts to change the basis such that $\ket{v}= U\ket{v'}$. Acting on the operator $A$ with $U$ is accomplished like this: $U^\dagger AU$. So for the trace to remain unchanged, we must have $Tr\{A\} = Tr\{U^\dagger AU\}$. Let's rewrite this in tensor notation for convenience using the Einstein summation convention:
	\[
		\begin{split}
		Tr\{A\} =& A_{ii} \\
		Tr\{U^\dagger AU\} =& U_{ij}^\dagger A_{jk}U_{ki} \\
		=& U_{ki}U_{ij}^\dagger A_{jk} \\
		=& \left( UU^\dagger\right)_{kj}A_{jk}
		\end{split}
	\]
	Since $U$ is unitary, $U^\dagger U = I$, which in Einstein notation, is the Kronecker delta:
	\[
		\begin{split}
		\left( U^\dagger U\right)_{kj}A_{jk} =& \delta_{kj} A_{jk} \\
		=& A_{kk} \\
		=& Tr\{A\}
		\end{split}
	\]
	
	(b) I have already shown that the trace is invariant under a change of basis. It is also well known that one can create a matrix through a change of basis such that the diagonals of the observable are its eigenvalues. 
	\[
		U^\dagger AU = \begin{pmatrix}
		a_1 & * & \cdots & * \\ 
		0 & a_2 & \cdots & * \\ 
		\vdots & \vdots & \ddots & \vdots \\ 
		0 & 0 & \cdots & a_n
		\end{pmatrix}
	\]
	The trace of $U^\dagger AU$ is then just the sum of the eigenvalues:
	\[
		Tr\{U^\dagger AU\} = \sum_i^n a_i
	\]
	And since I just showed in part a that the trace of A is unchanged under a change of basis, we have:
	\[
		\begin{split}		
		Tr\{A\} =& Tr\{U^\dagger AU\} \\
		=& \sum_i^n a_i
		\end{split}
	\]
	So the trace of a linear operator is the sum of its eigenvalues. But if there are degeneracies present, simply summing the eigenvalues is not enough since any degenerate eigenvalues would be present more than once. The degree of degeneracy, $g_n$ is the number of times a degenerate eigenvalue is present. Therefore we can simply multiply the degree of degeneracy by the eigenvalues in the trace:
	\[
		Tr\{A\} = \sum_i^k g_i a_i
	\]
	where $k$ is the number of unique eigenvalues.
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
	Let $\ket{\phi_n}$ be the eigenstates of a Hermitian operator $H$ ($H$ is the Hamiltonian of an arbitrary physical system for this problem). Assume that the states, $\ket{\phi_n}$ form a discrete orthonormal basis. The operator $U(m,n)$ is defined by:
	\[
		U(m,n) = \ket{\phi_m}\bra{\phi_n}
	\]
	(a) Calculate $U^\dagger(m,n)$ of $U(m,n)$.
	\\
	\\
	(b) Calculate the commutator, $\left[ H,U(m,n) \right]$
	\\
	\\
	(c) Prove the relation: $U(m,n)U^\dagger(p,q) = \delta_{nq}U(m,p)$
	\\
	\\
	(d) Calculate $Tr\{U(m,n)\}$, the trace of the operator $U(m,n)$.
	\\
	\\
	(e) Let $A$ be an operator with matrix elements, $A_{mn}=\braket{\phi_m|A|\phi_n}$. Prove the relation: $A=\sum_{m,n}A_{mn}U(m,n)$
	\\
	\\
	(f) Show that $A_{pq}=Tr\{AU^\dagger(m,n)\}$.
	\\
	\\
	\textbf{Solution}
	\\
	\\
	(a) 
	\[
		\begin{split}
		U(m,n) =& \ket{\phi_m}\bra{\phi_n} \\
		U^\dagger(m,n)=&\left[ \ket{\phi_m}\bra{\phi_n} \right]^\dagger \\
		=& \bra{\phi_n}^\dagger \ket{\phi_m}^\dagger \\
		=& \ket{\phi_n}\bra{\phi_m}
		\end{split}
	\]
	(b) 
	\[
		\begin{split}
		\left[ H,U(m,n) \right] =& HU(m,n)-U(m,n)H \\
		=&H\ket{\phi_m}\bra{\phi_n} - \ket{\phi_m}\bra{\phi_n}H
		\end{split}
	\]
	Since $\ket{\phi_n}$ is an eigenstate of $H$, we can say that $H\ket{\phi_n}=E_n\ket{\phi_n}$ and also that the hermitian conjugate of this is also true: $\bra{\phi_n}H=E_n\bra{\phi_n}$. Note that since $H$ is hermitian, $H^\dagger = H$, so in the previous equation I simply left it written as $H$. Using this, the commutation relation can be rewritten:
	\[
		\begin{split}
		H\ket{\phi_m}\bra{\phi_n} - \ket{\phi_m}\bra{\phi_n}H =& E_m\ket{\phi_m}\bra{\phi_n} - E_n\ket{\phi_m}\bra{\phi_n} \\
		=&\left( E_m-E_n \right) \ket{\phi_m}\bra{\phi_n} \\
		=& \left( E_m-E_n \right) U(m,n)
		\end{split}
	\]
	(c) Using the definition of $U^\dagger$ determined in part (a):
	\[
		\begin{split}
		U(m,n)U^\dagger(p,q) =& \ket{\phi_m}\bra{\phi_n} (\ket{\phi_p}\bra{\phi_q})^\dagger \\
		=& \ket{\phi_m}\braket{\phi_n \rvert \phi_q}\bra{\phi_p} \\
		=& \ket{\phi_m}\delta_{nq}\bra{\phi_p} \\
		=&\delta{nq} \ket{\phi_m}\bra{\phi_p} \\
		=& \delta{nq}U(m,p)
		\end{split}
	\]
	(d) 
	\[
		\begin{split}
		Tr\{U(m,n)\} =& \sum_i \braket{i\rvert U(m,n)\rvert i} \\
		=& \sum_i \braket{i\rvert m}\braket{n\rvert i}
		\end{split}
	\]
	Each separate bra-ket is just a number, so the order can be readily changed. If we swap the order we can clearly see the identity operator in there:
	\[
		\begin{split}
		Tr\{U(m,n)\} =& \sum_i \braket{i\rvert m}\braket{n\rvert i} \\
		=& \sum_i \braket{n\rvert i}\braket{i\rvert m} \\
		=& \braket{n\rvert I\rvert m} \\
		=& \braket{n\rvert m}
		\end{split}
	\]
	(e) 
	\[
		\begin{split}
		A_{mn}=&\braket{\phi_m\rvert A\rvert \phi_n} \\
		\sum_m A_{mn}\ket{\phi_m} =& \sum_m \ket{\phi_m}\braket{\phi_m\rvert A\rvert \phi_n} \\
		=& I A\ket{\phi_n} \\
		=& A\ket{\phi_n} \\
		\sum_{m,n} A_{mn}\ket{\phi_m}\bra{\phi_n} =& \sum_n A\ket{\phi_n}\bra{\phi_n} \\
		=& A I \\
		=& A \\
		\ket{\phi_m}\bra{\phi_n} =& U(m,n) \\
		\Rightarrow \sum_{m,n} A_{mn}U(m,n) =& A
		\end{split}
	\]
	(f) 
		\[
			\begin{split}
			Tr\{AU^\dagger(m,n)\} =& \sum_i \braket{i\rvert AU^\dagger(m,n)\rvert i} \\
			=& \sum_i \braket{i \rvert A\rvert \phi_n}\braket{\phi_m\rvert i} \\
			=& \sum_i \braket{\phi_m\rvert i}\braket{i \rvert A\rvert \phi_n} \\
			=& \braket{\phi_m\rvert IA\rvert \phi_n} \\
			=& \braket{\phi_m\rvert A\rvert \phi_n} \\
			=& A_{mn}
			\end{split}
		\]
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
	Consider the even operator $A$ and the odd operator $B$. Let $F(A)$ and $F(B)$ be the functions of these operators. It is always possible to expand the function $F(A)$ in a power series; same for $F(B)$.
	\\
	\\
	(a) Show that $F(A)=e^A$ has a definite parity, whereas $F(B)=e^B$ does not.	
	\\
	\\
	(b) Show that when $\ket{\phi_C}$ is an eigenvector of a Hermitian operator, $C$, with the eigenvalue of c, $\ket{\phi_C}$ is also an eigenvector of $F(C)$, with the eigenvalue $F(c)$.
	\\
	\\
	(c) If $\ket{\phi_a}$ is an eigenvector of $F(A)$, calculate the matrix element $\braket{\phi_a \rvert B \rvert \phi_a}$.
	\\
	\\
	(d) As an application of the result of part b, calculate the function $e^C$ if the matrix $C$ is given by:
	\[
		C=\begin{pmatrix}
		1 & 0 \\
		0 & -1 \end{pmatrix}
	\]
	\\
	\\
	(e) Comnpare the three following functions: $F(A)F(B)$, $F(B)F(A)$, and $F(A+B)$. Are they equal? If not, why?
	\\
	\\
	(f) Repeat query in part e if the operator $B$ is replaced by the parity operator.
	\\
	\\
	\textbf{Solution}
	\\
	\\
	(a) We can rewrite both functions of operators in their power series representations:
	\[
		\begin{split}
		F(A) =& \sum_n\frac{1}{n!}\frac{d^{n}F(A)}{dA^n}\bigg\rvert_{A=0}A^n \\
		=& \sum_n \frac{1}{n!}A^n \\
		F(B) =& \sum_n\frac{1}{n!}\frac{d^{n}F(B)}{dB^n}\bigg\rvert_{B=0}B^n \\
		=& \sum_n \frac{1}{n!}B^n
		\end{split}
	\]
	So let's check the parity of these operators. As we learned in lecture, for even operators, $\Pi A \Pi=A$, and for odd operators, $\Pi B\Pi=-B$. Let's apply this to $F(A)$ and $F(B)$ to see what parity they have.
	\[
		\begin{split}
		\Pi F(A) \Pi= \sum_n\frac{1}{n!}\Pi A^n \Pi \\
		\Pi F(B) \Pi= \sum_n\frac{1}{n!}\Pi B^n \Pi
		\end{split}
	\]
	What is the parity of an operator to the n-th power? First recall that $\Pi\Pi=1$ since it is unitary and Hermitian.
	\[
		\begin{split}
		\Pi A^n \Pi =& \Pi A\times A\times A\times \cdots \Pi\\
		=& (\Pi A \Pi)\times(\Pi A \Pi)\times(\Pi A \Pi)\times\cdots\times(\Pi A \Pi) \\
		=& A\times A\times A\times \cdots \\
		=& A^n \\
		\Pi B^n \Pi =& \Pi B\times B\times B\times \cdots \Pi\\
		=& (\Pi B \Pi)\times(\Pi B \Pi)\times(\Pi B \Pi)\times\cdots\times(\Pi B \Pi) \\
		=& (-B)\times (-B)\times (-B)\times \cdots \\
		=& (-1)^nB^n
		\end{split}
	\]
	\[
	\begin{split}
	\Pi F(A) \Pi=& \sum_n\frac{1}{n!}A^n = F(A)\\
	\Pi F(B) \Pi=& \sum_n\frac{1}{n!}(-1)^nB^n \neq \pm F(B)
	\end{split}
	\]
	For the even operator, the number of factors does not matter. We very clearly have that $F(A)$ is an even operator.
	\\
	\\
	For the odd operator, $B$, the parity depends on how many factors of B there are. For the full Taylor series, that is when the series converges to the exact value of $F(B)$, there are an infinite number of factors. This means $(-1)^n$ is impossible to evaluate and so the parity of $F(B)$ is impossible to determine. F(B) has no definite parity.
	\\
	\\
	(b) We define the operator, $C$, like this:
	\[
		C\ket{\phi_C} = c\ket{\phi_C}
	\]
	And we can define $F(C)$ as a Taylor series expanded about $C=0$.
	\[
		\begin{split}
		F(C)=&\sum_n\frac{1}{n!}\frac{d^nF(C)}{dC^n}\bigg\rvert_{C=0}C^n \\
		F(C)\ket{\phi_C} =& \sum_n\frac{1}{n!}\frac{d^nF(C)}{dC^n}\bigg\rvert_{C=0}C^n\ket{\phi_C}
		\end{split}
	\]
	The derivative part of the series expansion is just a number. The only part containing the operator itself is the $C^n$ factor.
	\[
		\begin{split}
		C^n\ket{\phi_C}=&C\times C\times \cdots \times C \ket{\phi_C} \\
		=& c\times c\times \cdots \times c \ket{\phi_C} \\
		=& c^n \ket{\phi_C} \\
		\Rightarrow F(C)\ket{\phi_C} =& \sum_n\frac{1}{n!}\frac{d^nF(C)}{dC^n}\bigg\rvert_{C=0}C^n\ket{\phi_C} \\
		=& \sum_n\frac{1}{n!}\frac{d^nF(C)}{dC^n}\bigg\rvert_{C=0}c^n\ket{\phi_C} \\
		=& F(c)\ket{\phi_C}
		\end{split}
	\]
	(c) 
	\[
		\begin{split}
		\braket{\phi_a\rvert B\rvert\phi_a} =& -\braket{\phi_a\rvert \Pi B\Pi\rvert\phi_a} \\
		=& -\braket{\phi_a\rvert B\rvert\phi_a} \\
		=&0
		\end{split}
	\]
	This is true because $B$ is odd and the eigenvectors are of the same parity.
	\\
	\\
	(d) As shown previously, we must write any function of an operator as a power series:
	\[
		\begin{split}
		F(C)=&e^C \\
		=& \sum_n \frac{1}{n!}\frac{d^nF(C)}{dC^n}\bigg\rvert_{C=0}C^n \\
		=& \sum_n \frac{1}{n!}C^n \\
		\end{split}
	\]
	Now let's look at the behavior of the given operator, $C$ under repeated exponentiation.
	\[
		\begin{split}
		C=&\begin{pmatrix}
		1 & 0 \\
		0 & -1 \end{pmatrix} \\
		C^2 =& \begin{pmatrix}
		1 & 0 \\
		0 & -1 \end{pmatrix}\begin{pmatrix}
		1 & 0 \\
		0 & -1 \end{pmatrix} \\
		=& \begin{pmatrix}
		1 & 0 \\
		0 & 1 \end{pmatrix} \\
		=& I \\
		C^4 =& C^2C^2 \\
		=&II\\
		=& I
		\end{split}
	\]
	So for all $n=$ even, we have \(C^n=I\). Let's look at odd $n$.
	\[
	\begin{split}
	C^3 =& C^2C \\
	=& IC \\
	=& C
	\end{split}
	\]
	So for all $n=$ odd, we have \(C^n=C\). So let's go back to our definition of $F(C)$ and split it between even and odd. I'll let $n=$ even integers and $m=$ odd integers.
	\[
		\begin{split}
		\sum_n \frac{1}{n!} I + \sum_m \frac{1}{m!} C
		=& \begin{pmatrix}
		\sum_n \frac{1}{n!}+\sum_m \frac{1}{m!} & 0 \\
		0 & \sum_n \frac{1}{n!}-\sum_m \frac{1}{m!} \end{pmatrix} \\
		\Rightarrow F(C)=& \begin{pmatrix} 
		e & 0 \\
		0 &1/e \end{pmatrix}
		\end{split}
	\]
 The sums above are well-known and they converge to $e$ and $1/e$ as I put in the final result. (see \url{https://en.wikipedia.org/wiki/E_(mathematical_constant})
 \\
 \\
 (e) 
	 \[
		 \begin{split}
		 F(A) =& \sum_n \frac{1}{n!}\frac{d^nF(A)}{dA^n}\bigg\rvert_{A=0}A^n \\
		 F(B) =& \sum_m \frac{1}{m!}\frac{d^mF(B)}{dB^m}\bigg\rvert_{B=0}B^n \\
		 F(A+B) =& \sum_n \frac{1}{n!}\frac{d^nF(A+B)}{d(A+B)^n}\bigg\rvert_{A+B=0}(A+B)^n \\
		 \end{split}
	 \]
	 We can see that $F(A)F(B) = F(B)F(A)$ only if $[A^n,B^m]=0$, which can not be said to be true in general. $F(A+B) \neq F(A)F(B)$
	 \\
	 \\
	 (f) If B were replaced by the parity operator, $\Pi$:
	 \[
		 \begin{split} 
		 F(\Pi) =& \sum_m \frac{1}{m!}\frac{d^mF(\Pi)}{d\Pi^m}\bigg\rvert_{\Pi=0}\Pi^n \\
		 F(A+\Pi) =& \sum_n \frac{1}{n!}\frac{d^nF(A+\Pi)}{d(A+\Pi)^n}\bigg\rvert_{A+\Pi=0}(A+\Pi)^n \\
		 \end{split}
	 \]
	 Then $F(A)F(\Pi) = F(\Pi)F(A)$ since A has even parity and $A$ commutes with the parity operator. But $F(A+\Pi) \neq F(A)F(\Pi)$ and $F(A+\Pi) \neq F(\Pi)F(A)$
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
	Consider a three-dimensional state space and the following set of operators:
	\[
		A= \begin{pmatrix}
		1 & 1 & 0 \\
		1 & 0 & 0 \\
		0 & 0 & 0 \end{pmatrix}, \quad
		B = \begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 0 \end{pmatrix}, \quad
		C= \begin{pmatrix}
		0 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1 \end{pmatrix}
	\]
	Find all possible CSCOs. That is, determine whether or not each of the sets: $\{A\}$, $\{B\}$, $\{C\}$, $\{A,B\}$, $\{A,C\}$, $\{B,C\}$, $\{A,B,C\}$ constitutes a valid CSCO.
	\\
	\\
	\textbf{Solution}
	\\
	\\
	I'll take each set individually and determine if they constitute a valid CSCO. First the sets of single operators:
	\\
	\\
	$\{A\}$ \\
	First determine the eigenvalues by solving the characteristic equation:
	\[
		\begin{split}
		\det(A-\lambda I) =& \begin{vmatrix} 
		1-\lambda & 1 & 0 \\
		1 & -\lambda & 0 \\
		0 & 0 & -\lambda \end{vmatrix} \\
		=& (1-\lambda)\lambda^2 + \lambda \\
		=& -\lambda^3+\lambda^2+\lambda  \\
		=& -\lambda(\lambda^2-\lambda-1) = 0 \\
		\Rightarrow \lambda =& 0, \frac{1}{2}(1+\sqrt{5}), \frac{1}{2}(1-\sqrt{5}) \\		
		\end{split}
	\]
	Since none of the eigenvalues are degenerate, $\{A\}$ is a CSCO.
	\\
	\\
	$\{B\}$ is diagonal, so by simple inspection we see that there are two eigenvalues, $\lambda = 1,0$ and that $\lambda = 1$ is degenerate. Therefore $\{B\}$ is not a CSCO.
	\\
	\\
	$\{C\}$ has the same eigenvalues and degeneracies that $\{B\}$ has. It is also not a CSCO.
	\\
	\\
	$\{A,B\}$ \\
	The first step with sets of more than one operator is to determine if they commute:
	\[
		\begin{split}
		\left[ A,B \right] =& 
		\begin{pmatrix}
		1 & 1 & 0 \\
		1 & 0 & 0 \\
		0 & 0 & 0 \end{pmatrix}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 0 \end{pmatrix} - 
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 0 \end{pmatrix}
		\begin{pmatrix}
		1 & 1 & 0 \\
		1 & 0 & 0 \\
		0 & 0 & 0 \end{pmatrix} \\
		=& \begin{pmatrix}
		1 & 1 & 0 \\
		1 & 0 & 0 \\
		0 & 0 & 0 \end{pmatrix} - 
		\begin{pmatrix}
		1 & 1 & 0 \\
		1 & 0 & 0 \\
		0 & 0 & 0 \end{pmatrix} \\
		=& 0
		\end{split}
	\]
	Now let's find the eigenvectors and see if we can construct a common set starting with A:\\
	$\lambda = 0$:
	\[
		\begin{split}
		\begin{pmatrix}
		1 & 1 & 0 \\
		1 & 0 & 0 \\
		0 & 0 & 0 \end{pmatrix}
		\begin{pmatrix}
		c_1 \\ c_2 \\ c_3
		\end{pmatrix} =& 
		\begin{pmatrix}
		0 \\ 0 \\ 0
		\end{pmatrix} \\
		c_1+c_2=&0 \\
		c_1 =& 0 \\
		c_2 =& 0 \\
		\Rightarrow \vec{v}_{\lambda=0} =& \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
		\end{split}
	\]
	$\lambda = \frac{1}{2}(1+\sqrt{5})$
	\[
		\begin{split}
		\begin{pmatrix}
		\frac{1}{2}(1-\sqrt{5}) & 1 & 0 \\
		1 & -\frac{1}{2}(1+\sqrt{5}) & 0 \\
		0 & 0 & -\frac{1}{2}(1+\sqrt{5}) \end{pmatrix}
		\begin{pmatrix}
		c_1 \\ c_2 \\ c_3
		\end{pmatrix} =& 
		\begin{pmatrix}
		0 \\ 0 \\ 0
		\end{pmatrix} \\
		\frac{c_1}{2}(1-\sqrt{5})+c_2=&0 \\
		c_1-\frac{c_2}{2}(1+\sqrt{5})=&0 \\
		-\frac{c_3}{2}(1+\sqrt{5})=&0 \\
		c_1 = 1+\sqrt{5} \\ 
		c_2 = 2 \\
		c_3 = 0 \\
		\Rightarrow \vec{v}_{\lambda=\frac{1}{2}(1+\sqrt{5})} =& \frac{1}{\sqrt{2(5+\sqrt{5})}}\begin{pmatrix} 1+\sqrt{5} \\ 2 \\ 0 \end{pmatrix}
		\end{split}
	\]
	$\lambda = \frac{1}{2}(1-\sqrt{5})$
	\[
	\begin{split}
	\begin{pmatrix}
	\frac{1}{2}(1+\sqrt{5}) & 1 & 0 \\
	1 & -\frac{1}{2}(1-\sqrt{5}) & 0 \\
	0 & 0 & -\frac{1}{2}(1-\sqrt{5}) \end{pmatrix}
	\begin{pmatrix}
	c_1 \\ c_2 \\ c_3
	\end{pmatrix} =& 
	\begin{pmatrix}
	0 \\ 0 \\ 0
	\end{pmatrix} \\
	\frac{-c_1}{2}(1+\sqrt{5})+c_2=&0 \\
	c_1-\frac{c_2}{2}(1-\sqrt{5})=&0 \\
	-\frac{c_3}{2}(1-\sqrt{5})=&0 \\
	c_1 = 1-\sqrt{5} \\ 
	c_2 = 2 \\
	c_3 = 0 \\
	\Rightarrow \vec{v}_{\lambda=\frac{1}{2}(1-\sqrt{5})} =& \frac{1}{\sqrt{2(5-\sqrt{5})}}\begin{pmatrix} 1-\sqrt{5} \\ 2 \\ 0 \end{pmatrix}
	\end{split}
	\]
	Now to determine if the eigenvectors of A are also eigenvectors of B. 
	\[
		\begin{split}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 0 \end{pmatrix}
		\begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix} =& \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix}
		\end{split}
	\]
	This is an eigenvector of B with $\lambda = 0$. But note that for A, $\lambda = 0$. This vector is an eigenvector of both A and B with the same eigenvalue. Therefore this does not get rid of the degeneracy. 
	\\
	\\
	$\{A,B\}$ is not a CSCO.
	\\
	\\
	$\{A,C\}$ \\
	Do A and C commute?
	\[
	\begin{split}
	\left[ A,C \right] =& 
	\begin{pmatrix}
	1 & 1 & 0 \\
	1 & 0 & 0 \\
	0 & 0 & 0 \end{pmatrix}
	\begin{pmatrix}
	0 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1 \end{pmatrix} - 
	\begin{pmatrix}
	0 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1 \end{pmatrix}
	\begin{pmatrix}
	1 & 1 & 0 \\
	1 & 0 & 0 \\
	0 & 0 & 0 \end{pmatrix} \\
	=& \begin{pmatrix}
	0 & 1 & 0 \\
	0 & 0 & 0 \\
	0 & 0 & 0 \end{pmatrix} - 
	\begin{pmatrix}
	0 & 0 & 0 \\
	1 & 0 & 0 \\
	0 & 0 & 0 \end{pmatrix} \\
	\neq& 0
	\end{split}
	\]
	\\
	\\
	$\{A,C\}$ is not a CSCO.
	\\
	\\
	$\{B,C\}$ \\
	\[
	\begin{split}
	\left[ B,C \right] =& 
	\begin{pmatrix}
	1 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 0 \end{pmatrix}
	\begin{pmatrix}
	0 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1 \end{pmatrix} - 
	\begin{pmatrix}
	0 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 1 \end{pmatrix}
	\begin{pmatrix}
	1 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 0 \end{pmatrix} \\
	=& \begin{pmatrix}
	0 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 0 \end{pmatrix} - 
	\begin{pmatrix}
	0 & 0 & 0 \\
	0 & 1 & 0 \\
	0 & 0 & 0 \end{pmatrix} \\
	=& 0
	\end{split}
	\]
	B and C do commute. What are their eigenvectors? \\
	For B:
	\[
		\lambda = 0
		\begin{split}
		\begin{pmatrix}
		1 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 0 \end{pmatrix}
		\begin{pmatrix} c_1 \\ c_2 \\ c_3 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} \\
		c_1 = 0, \; c_2=0 \\	
		\vec{v} = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
		\end{split}
	\]
	\[
		\lambda = 1
		\begin{split}
		\begin{pmatrix}
		0 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 & -1 \end{pmatrix}
		\begin{pmatrix} c_1 \\ c_2 \\ c_3 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} \\
		c_3 = 0 \\	
		\vec{v}_1 = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix},\; \vec{v}_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}
		\end{split}
	\]
	The set of eignevectors for $B$ are:
	\[
		\begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix},\;\begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix},\;\begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}
	\]
	For C:
	\[
		\lambda = 0
		\begin{split}
		\begin{pmatrix}
		0 & 0 & 0 \\
		0 & 1 & 0 \\
		0 & 0 & 1 \end{pmatrix}
		\begin{pmatrix} c_1 \\ c_2 \\ c_3 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} \\
		c_2 = 0, \; c_3=0 \\	
		\vec{v} = \begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix}
		\end{split}
	\]
	\[
		\lambda = 1
		\begin{split}
		\begin{pmatrix}
		-1 & 0 & 0 \\
		0 & 0 & 0 \\
		0 & 0 & 0 \end{pmatrix}
		\begin{pmatrix} c_1 \\ c_2 \\ c_3 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} \\
		c_1 = 0 \\	
		\vec{v}_1 = \begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix},\; \vec{v}_2 = \begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix}
		\end{split}
	\]
	The set of eignevectors for $C$ are:
	\[
		\begin{pmatrix} 1 \\ 0 \\ 0 \end{pmatrix},\;\begin{pmatrix} 0 \\ 0 \\ 1 \end{pmatrix},\;\begin{pmatrix} 0 \\ 1 \\ 0 \end{pmatrix}
	\]
	The set of eigenvectors for B and C have one vector with the same eigenvalue in common, so $\{B,C\}$ are not a CSCO.
	\\
	\\
	$\{A,B,C\}$\\
	Since we already know that not all pairs in this set commute, this set cannot form a CSCO.
\end{homeworkProblem}

\end{document}
